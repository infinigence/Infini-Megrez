# Megrez-3B-Instruct
<p align="center">
    <img src="../assets/megrez_logo.png" width="400"/>
<p>

<p align="center">
        ğŸ”— <a href="https://github.com/infinigence/Infini-Megrez">GitHub</a>&nbsp&nbsp | &nbsp&nbspğŸ  <a href="https://cloud.infini-ai.com/genstudio/model/mo-c73owqiotql7lozr">Infini-AI mass</a>&nbsp&nbsp | &nbsp&nbspğŸ“– <a href="../assets/wechat-official.jpg">WeChat Official</a>&nbsp&nbsp | &nbsp&nbspğŸ’¬ <a href="../assets/wechat-group.jpg">WeChat Groups</a>&nbsp&nbsp   
</p>
<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> | <a href="https://github.com/infinigence/Infini-Megrez/blob/main/megrez/README_EN.md">English</a>
    <p>
</h4>

## æ¨¡å‹ç®€ä»‹
Megrez-3B-Instructæ˜¯ç”±æ— é—®èŠ¯ç©¹ï¼ˆ[Infinigence AI](https://cloud.infini-ai.com/platform/ai)ï¼‰å®Œå…¨è‡ªä¸»è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ã€‚Megrez-3Bæ—¨åœ¨é€šè¿‡è½¯ç¡¬ååŒç†å¿µï¼Œæ‰“é€ ä¸€æ¬¾æé€Ÿæ¨ç†ã€å°å·§ç²¾æ‚ã€ææ˜“ä¸Šæ‰‹çš„ç«¯ä¾§æ™ºèƒ½è§£å†³æ–¹æ¡ˆã€‚Megrez-3Bå…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š
1. é«˜ç²¾åº¦ï¼šMegrez-3Bè™½ç„¶å‚æ•°è§„æ¨¡åªæœ‰3Bï¼Œä½†é€šè¿‡æå‡æ•°æ®è´¨é‡ï¼ŒæˆåŠŸå¼¥åˆæ¨¡å‹èƒ½åŠ›ä»£å·®ï¼Œå°†ä¸Šä¸€ä»£14Bæ¨¡å‹çš„èƒ½åŠ›æˆåŠŸå‹ç¼©è¿›3Bå¤§å°çš„æ¨¡å‹ï¼Œåœ¨ä¸»æµæ¦œå•ä¸Šå–å¾—äº†ä¼˜ç§€çš„æ€§èƒ½è¡¨ç°ã€‚
2. é«˜é€Ÿåº¦ï¼šæ¨¡å‹å°â‰ é€Ÿåº¦å¿«ã€‚Megrez-3Bé€šè¿‡è½¯ç¡¬ååŒä¼˜åŒ–ï¼Œç¡®ä¿äº†å„ç»“æ„å‚æ•°ä¸ä¸»æµç¡¬ä»¶é«˜åº¦é€‚é…ï¼Œæ¨ç†é€Ÿåº¦é¢†å…ˆåŒç²¾åº¦æ¨¡å‹æœ€å¤§300%ã€‚
3. ç®€å•æ˜“ç”¨ï¼šæ¨¡å‹è®¾è®¡ä¹‹åˆæˆ‘ä»¬è¿›è¡Œäº†æ¿€çƒˆçš„è®¨è®ºï¼šåº”è¯¥åœ¨ç»“æ„è®¾è®¡ä¸Šç•™å‡ºæ›´å¤šè½¯ç¡¬ååŒçš„ç©ºé—´ï¼ˆå¦‚ReLUã€ç¨€ç–åŒ–ã€æ›´ç²¾ç®€çš„ç»“æ„ç­‰ï¼‰ï¼Œè¿˜æ˜¯ä½¿ç”¨ç»å…¸ç»“æ„ä¾¿äºå¼€å‘è€…ç›´æ¥ç”¨èµ·æ¥ï¼Ÿæˆ‘ä»¬é€‰æ‹©äº†åè€…ï¼Œå³é‡‡ç”¨æœ€åŸå§‹çš„LLaMAç»“æ„ï¼Œå¼€å‘è€…æ— éœ€ä»»ä½•ä¿®æ”¹ä¾¿å¯å°†æ¨¡å‹éƒ¨ç½²äºå„ç§å¹³å°ï¼Œæœ€å°åŒ–äºŒæ¬¡å¼€å‘å¤æ‚åº¦ã€‚
4. ä¸°å¯Œåº”ç”¨ï¼šæˆ‘ä»¬æä¾›äº†å®Œæ•´çš„WebSearchæ–¹æ¡ˆã€‚æˆ‘ä»¬å¯¹æ¨¡å‹è¿›è¡Œäº†é’ˆå¯¹æ€§è®­ç»ƒï¼Œä½¿æ¨¡å‹å¯ä»¥è‡ªåŠ¨å†³ç­–æœç´¢è°ƒç”¨æ—¶æœºï¼Œåœ¨æœç´¢å’Œå¯¹è¯ä¸­è‡ªåŠ¨åˆ‡æ¢ï¼Œå¹¶æä¾›æ›´å¥½çš„æ€»ç»“æ•ˆæœã€‚æˆ‘ä»¬æä¾›äº†å®Œæ•´çš„éƒ¨ç½²å·¥ç¨‹ä»£ç  [github](https://github.com/infinigence/InfiniWebSearch)ï¼Œç”¨æˆ·å¯ä»¥åŸºäºè¯¥åŠŸèƒ½æ„å»ºå±äºè‡ªå·±çš„Kimiæˆ–Perplexityï¼Œå…‹æœå°æ¨¡å‹å¸¸è§çš„å¹»è§‰é—®é¢˜å’ŒçŸ¥è¯†å‚¨å¤‡ä¸è¶³çš„å±€é™ã€‚

## åŸºç¡€ä¿¡æ¯
* Architecture: Llama-2 with GQA  
* Context length: 32K tokens  
* Params (Total): 2.92B  
* Params (Backbone only, w/o Emb or Softmax):  2.29B    
* Vocab Size: 122880  
* Training data: 3T tokens  
* Supported languages: Chinese & English

## æ€§èƒ½
æˆ‘ä»¬ä½¿ç”¨å¼€æºè¯„æµ‹å·¥å…· [OpenCompass](https://github.com/open-compass/opencompass) å¯¹ Megrez-3B-Instruct è¿›è¡Œäº†è¯„æµ‹ã€‚éƒ¨åˆ†è¯„æµ‹ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚

é€Ÿåº¦ç²¾åº¦æ¨¡å‹å¤§å°æ•£ç‚¹å›¾å¦‚ä¸‹ï¼Œä½ç½®è¶Šé è¿‘å³ä¸Šè¡¨æ˜æ¨¡å‹è¶Šå¥½è¶Šå¿«ã€‚
![MMLU](../assets/mmlu.jpg)
![MTBench](../assets/mtbench.jpg)

æ›´å¤šæŒ‡æ ‡æ•°æ®è¯·è§ ğŸ¤— [Megrez-3B-Instruct](https://huggingface.co/Infinigence/Megrez-3B-Instruct)

### é€Ÿåº¦
|                | æ¨ç†é€Ÿåº¦(tokens/s) |
|:--------------:|:-----------------:|
| Megrez-3B-Instruct    |      2329.4        |
| Qwen2.5-1.5B          |      3318.8        |
| Qwen2-1.5B            |      3299.5        |
| Qwen2.5-3B-Instruct   |      2248.3        |
| MiniCPM-2B            |      1930.8        |
| Qwen1.5-4B            |      1837.9        |
| Phi-3.5-mini-instruct |      1559.1        |
| Yi-1.5-6B             |      1542.7        |
| Qwen1.5-7B            |      1282.3        |
| Qwen2.5-7B            |      1283.4        |
| Qwen2-7B              |      1279.4        |
| Meta-Llama-3.1-8B     |      1255.9        |
| GLM-4-9B-chat         |      1076.1        |
| MiniCPM3-4B           |      901.1         |
| Baichuan2-13B-Base    |      756.7         |
| Qwen1.5-14B           |      735.6         |

- æµ‹é€Ÿé…ç½®è¯¦è§ <a href="https://huggingface.co/Infinigence/Megrez-3B-Instruct/blob/main/README_SPEED.md">README_SPEED.md</a>

## WebSearch
æˆ‘ä»¬æ¨¡å‹è¿›è¡Œäº†é’ˆå¯¹æ€§è®­ç»ƒï¼Œå¹¶æä¾›äº†å®Œæ•´çš„å·¥ç¨‹éƒ¨ç½²æ–¹æ¡ˆã€‚[InfiniWebSearch](https://github.com/infinigence/InfiniWebSearch) å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š
1. è‡ªåŠ¨å†³å®šè°ƒç”¨æ—¶æœºï¼šè‡ªåŠ¨å†³ç­–æœç´¢è°ƒç”¨æ—¶æœºï¼Œåœ¨æœç´¢å’Œå¯¹è¯ä¸­è‡ªåŠ¨åˆ‡æ¢ï¼Œé¿å…ä¸€ç›´è°ƒç”¨æˆ–ä¸€ç›´ä¸è°ƒç”¨
2. ä¸Šä¸‹æ–‡ç†è§£ï¼šæ ¹æ®å¤šè½®å¯¹è¯ç”Ÿæˆåˆç†çš„æœç´¢queryæˆ–å¤„ç†æœç´¢ç»“æœï¼Œæ›´å¥½çš„ç†è§£ç”¨æˆ·æ„å›¾
3. å¸¦å‚è€ƒä¿¡æ¯çš„ç»“æ„åŒ–è¾“å‡ºï¼šæ¯ä¸ªç»“è®ºæ³¨æ˜å‡ºå¤„ï¼Œä¾¿äºæŸ¥éªŒ
4. ä¸€ä¸ªæ¨¡å‹ä¸¤ç§ç”¨æ³•ï¼šé€šè¿‡sys promptåŒºåˆ†WebSearchåŠŸèƒ½å¼€å¯ä¸å¦ï¼Œå…¼é¡¾LLMçš„é«˜ç²¾åº¦ä¸WebSearchçš„ç”¨æˆ·ä½“éªŒï¼Œä¸¤ç§èƒ½åŠ›ä¸ä¹±çªœ

æˆ‘ä»¬å¯¹æ¨¡å‹è¿›è¡Œäº†é’ˆå¯¹æ€§è®­ç»ƒï¼Œä½¿æ¨¡å‹å¯ä»¥è‡ªåŠ¨å†³ç­–æœç´¢è°ƒç”¨æ—¶æœºï¼Œåœ¨æœç´¢å’Œå¯¹è¯ä¸­è‡ªåŠ¨åˆ‡æ¢ï¼Œå¹¶æä¾›æ›´å¥½çš„æ€»ç»“æ•ˆæœã€‚æˆ‘ä»¬æä¾›äº†å®Œæ•´çš„éƒ¨ç½²å·¥ç¨‹ä»£ç  ï¼Œç”¨æˆ·å¯ä»¥åŸºäºè¯¥åŠŸèƒ½æ„å»ºå±äºè‡ªå·±çš„Kimiæˆ–Perplexityï¼Œå…‹æœå°æ¨¡å‹å¸¸è§çš„å¹»è§‰é—®é¢˜å’ŒçŸ¥è¯†å‚¨å¤‡ä¸è¶³çš„å±€é™ã€‚
![WebSearchDemo](../assets/websearch_demo.gif)

## å¿«é€Ÿä¸Šæ‰‹
### åœ¨çº¿ä½“éªŒ
[MaaS (æ¨è)](https://cloud.infini-ai.com/genstudio/model/mo-c73owqiotql7lozr)  

### æ¨ç†å‚æ•°
- å¯¹äºå¯¹è¯ã€æ–‡ç« æ’°å†™ç­‰å…·æœ‰ä¸€å®šéšæœºæ€§æˆ–å‘æ•£æ€§çš„è¾“å‡ºï¼Œå¯ä»¥é‡‡ç”¨ temperature=0.7ç­‰å‚æ•°è¿›è¡Œæ¨ç†
- å¯¹äºæ•°å­¦ã€é€»è¾‘æ¨ç†ç­‰ç¡®å®šæ€§è¾ƒé«˜çš„è¾“å‡ºï¼Œå»ºè®®ä½¿ç”¨ **temperature=0.2** çš„å‚æ•°è¿›è¡Œæ¨ç†ï¼Œä»¥å‡å°‘é‡‡æ ·å¸¦æ¥çš„å¹»è§‰å½±å“ï¼Œè·å¾—æ›´å¥½çš„æ¨ç†èƒ½åŠ›

### ğŸ¤— Huggingface æ¨ç†
å®‰è£…transformersåï¼Œè¿è¡Œä»¥ä¸‹ä»£ç ã€‚
``` python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

path = "Infinigence/Megrez-3B-Instruct"
device = "cuda"

tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map=device, trust_remote_code=True)

messages = [
    {"role": "user", "content": "è®²è®²é»„ç„–é¸¡çš„åšæ³•ã€‚"},
]
model_inputs = tokenizer.apply_chat_template(messages, return_tensors="pt", add_generation_prompt=True).to(device)

model_outputs = model.generate(
    model_inputs,
    do_sample=True,
    max_new_tokens=1024,
    top_p=0.9,
    temperature=0.2
)

output_token_ids = [
    model_outputs[i][len(model_inputs[i]):] for i in range(len(model_inputs))
]

responses = tokenizer.batch_decode(output_token_ids, skip_special_tokens=True)[0]
print(responses)
```

### ğŸ¤– ModelScope æ¨ç†
```python
import torch
from modelscope import AutoTokenizer, AutoModelForCausalLM

model_path = "Infinigence/Megrez-3B-Instruct"
device = "cuda"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_romote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=device, trust_remote_code=True)

messages = [{"role": "user", "content": "è®²è®²é»„ç„–é¸¡çš„åšæ³•ã€‚"}]
model_inputs = tokenizer.apply_chat_template(messages, return_tensors="pt", add_generation_prompt=True).to(device)
model_outputs = model.generate(
    model_inputs,
    do_sample = True,
    max_new_tokens=2048,
    top_p=0.9,
    temperature=0.2
)

output_token_ids = [
    model_outputs[i][len(model_inputs[i]):] for i in range(len(model_inputs))
]
responses = tokenizer.batch_decode(output_token_ids, skip_special_tokens=True)[0]
print(responses)
```

### ğŸ’» vLLM æ¨ç†
 
- å®‰è£…vLLM
```bash
# Install vLLM with CUDA 12.1.
pip install vllm
```
- æµ‹è¯•æ ·ä¾‹
```python
from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

model_name = "Infinigence/Megrez-3B-Instruct"
prompt = [{"role": "user", "content": "è®²è®²é»„ç„–é¸¡çš„åšæ³•ã€‚"}]

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
input_text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)

llm = LLM(
    model=model_name,
    trust_remote_code=True,
    tensor_parallel_size=1
)
sampling_params = SamplingParams(top_p=0.9, temperature=0.2, max_tokens=1024)

outputs = llm.generate(prompts=input_text, sampling_params=sampling_params)

print(outputs[0].outputs[0].text)
```

## å¼€æºåè®®åŠä½¿ç”¨å£°æ˜
- åè®®ï¼šæœ¬ä»“åº“ä¸­ä»£ç ä¾ç…§ [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) åè®®å¼€æº
- å¹»è§‰ï¼šå¤§æ¨¡å‹å¤©ç„¶å­˜åœ¨å¹»è§‰é—®é¢˜ï¼Œç”¨æˆ·ä½¿ç”¨è¿‡ç¨‹ä¸­è¯·å‹¿å®Œå…¨ç›¸ä¿¡æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ã€‚è‹¥ç”¨æˆ·æƒ³è·å–æ›´ç¬¦åˆäº‹å®çš„ç”Ÿæˆå†…å®¹ï¼Œæ¨èåˆ©ç”¨æˆ‘ä»¬çš„WebSearchåŠŸèƒ½ï¼Œè¯¦è§ [InfiniWebSearch](https://github.com/paxionfull/InfiniWebSearch)ã€‚
- æ•°å­¦&æ¨ç†ï¼šå°æ¨¡å‹åœ¨æ•°å­¦å’Œæ¨ç†ä»»åŠ¡ä¸Šæ›´å®¹æ˜“å‡ºé”™è¯¯çš„è®¡ç®—è¿‡ç¨‹æˆ–æ¨ç†é“¾æ¡ï¼Œä»è€Œå¯¼è‡´æœ€ç»ˆç»“æœé”™è¯¯ã€‚ç‰¹åˆ«çš„ï¼Œå°æ¨¡å‹çš„è¾“å‡ºsoftmaxåˆ†å¸ƒç›¸æ¯”å¤§æ¨¡å‹æ˜æ˜¾ä¸å¤Ÿsharpï¼Œåœ¨è¾ƒé«˜temperatureä¸‹æ›´å®¹æ˜“å‡ºç°å¤šæ¬¡æ¨ç†ç»“æœä¸ä¸€è‡´çš„é—®é¢˜ï¼Œåœ¨æ•°å­¦/æ¨ç†ç­‰ç¡®å®šæ€§é—®é¢˜ä¸Šæ›´ä¸ºæ˜æ˜¾ã€‚æˆ‘ä»¬æ¨èåœ¨è¿™ç±»é—®é¢˜ä¸Šï¼Œè°ƒä½temperatureï¼Œæˆ–å°è¯•å¤šæ¬¡æ¨ç†éªŒè¯ã€‚
- System Promptï¼šå’Œç»å¤§å¤šæ•°æ¨¡å‹ä¸€æ ·ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­chat_templateé»˜è®¤çš„system promptï¼Œä»¥è·å¾—ç¨³å®šå’Œå¹³è¡¡çš„ä½“éªŒã€‚æœ¬æ¬¡æ¨¡å‹å‘å¸ƒå¼±åŒ–äº†è§’è‰²æ‰®æ¼”ç­‰æ¶‰åŠç‰¹å®šé¢†åŸŸåº”ç”¨æ–¹é¢çš„èƒ½åŠ›ï¼Œç”¨æˆ·è‹¥æœ‰ç‰¹å®šé¢†åŸŸçš„åº”ç”¨éœ€æ±‚ï¼Œæˆ‘ä»¬æ¨èåœ¨æœ¬æ¨¡å‹åŸºç¡€ä¸ŠæŒ‰éœ€è¿›è¡Œé€‚å½“å¾®è°ƒã€‚
- ä»·å€¼è§‚åŠå®‰å…¨æ€§ï¼šæœ¬æ¨¡å‹å·²å°½å…¨åŠ›ç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ï¼Œä½†ç”±äºæ•°æ®çš„å¤§ä½“é‡åŠå¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å¦‚æœå‡ºç°ä½¿ç”¨æœ¬å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚
